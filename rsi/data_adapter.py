"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ CSV –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
"""
import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__)

class DataAdapter:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ CSV –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def detect_format(df: pd.DataFrame) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö"""
        columns = set(df.columns.str.lower())
        
        if {'open', 'high', 'low', 'close'}.issubset(columns):
            return 'ohlcv'
        elif {'choppiness_index', 'volatility_percent', 'rsi_delta'}.issubset(columns):
            return 'indicators_only'
        elif 'close' in columns:
            return 'price_only'
        else:
            return 'unknown'
    
    @staticmethod
    def load_csv(filepath: str, **kwargs) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ CSV —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
            for sep in [',', ';', '\t']:
                try:
                    df = pd.read_csv(filepath, sep=sep, **kwargs)
                    if len(df.columns) > 1:  # –£—Å–ø–µ—à–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                        logger.info(f"CSV –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}', –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
                        return df
                except Exception:
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø—è—Ç—É—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            df = pd.read_csv(filepath, **kwargs)
            logger.info(f"CSV –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
            return df
            
        except Exception as e:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª: {e}")
    
    @staticmethod
    def clean_accumulated_data(df: pd.DataFrame) -> pd.DataFrame:
        """–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ accumulatedData —Ñ–∞–π–ª–æ–≤ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)"""
        df = df.copy()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        time_columns = ['open_time', 'close_time']
        for col in time_columns:
            if col in df.columns:
                try:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                    logger.info(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ {col} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É {col}: {e}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–ò–°–ö–õ–Æ–ß–ê–Ø –≤—Ä–µ–º–µ–Ω–Ω—ã–µ)
        numeric_columns = [
            'open', 'high', 'low', 'close', 'volume',
            'atr', 'atr_stop', 'atr_to_price_ratio',
            'fast_ema', 'slow_ema', 'ema_fast_deviation',
            'pchange', 'avpchange', 'gma', 'gma_smoothed',
            'positionBetweenBands', 'bollinger_position',
            'choppiness_index', 'volatility_percent',
            'rsi_volatility', 'adx', 'rsi_divergence', 'rsi_delta', 'linear_regression'
        ]
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∏—Å–∫–ª—é—á–∞—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ
        for col in numeric_columns:
            if col in df.columns and col not in time_columns:  # –ò—Å–∫–ª—é—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏!
                try:
                    # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    if df[col].dtype == 'object':
                        df[col] = df[col].astype(str).str.replace(',', '.')
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    logger.debug(f"–ö–æ–ª–æ–Ω–∫–∞ {col} –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø")
                    
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É {col}: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
        if 'open_time' in df.columns and not df['open_time'].isna().all():
            try:
                df = df.sort_values('open_time').reset_index(drop=True)
                logger.info("–î–∞–Ω–Ω—ã–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ open_time")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {e}")
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –∫—Ä–∏—Ç–∏—á–Ω—ã–º–∏ NaN (–≤ OHLC)
        critical_columns = ['open', 'high', 'low', 'close']
        available_critical = [col for col in critical_columns if col in df.columns]
        
        if available_critical:
            before_rows = len(df)
            df = df.dropna(subset=available_critical)
            after_rows = len(df)
            
            if before_rows != after_rows:
                logger.info(f"–£–¥–∞–ª–µ–Ω–æ {before_rows - after_rows} —Å—Ç—Ä–æ–∫ —Å NaN –≤ OHLC –¥–∞–Ω–Ω—ã—Ö")
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö NaN –≤ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            df[numeric_cols] = df[numeric_cols].ffill().bfill()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {df.shape}")
        logger.info(f"–ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {len(df.select_dtypes(include=[np.number]).columns)}")
        logger.info(f"–í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {len(df.select_dtypes(include=['datetime64']).columns)}")
        
        return df
    
    @staticmethod
    def adapt_to_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∫ —Ñ–æ—Ä–º–∞—Ç—É OHLCV"""
        df = df.copy()
        format_type = DataAdapter.detect_format(df)
        
        if format_type == 'ohlcv':
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ accumulatedData
            if 'open_time' in df.columns and 'atr' in df.columns:
                logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ accumulatedData - –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É")
                df = DataAdapter.clean_accumulated_data(df)
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ OHLCV
                required_cols = ['open', 'high', 'low', 'close']
                df = df.rename(columns={col: col.lower() for col in df.columns})
                
                missing = [col for col in required_cols if col not in df.columns]
                if missing:
                    raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing}")
                    
        elif format_type == 'price_only':
            # –¢–æ–ª—å–∫–æ —Ü–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è - —Å–æ–∑–¥–∞–µ–º OHLC
            if 'close' not in df.columns:
                raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'close'")
            
            df['open'] = df['close'].shift(1).fillna(df['close'].iloc[0])
            df['high'] = df[['open', 'close']].max(axis=1) * (1 + np.random.uniform(0, 0.01, len(df)))
            df['low'] = df[['open', 'close']].min(axis=1) * (1 - np.random.uniform(0, 0.01, len(df)))
            
            logger.info("–°–æ–∑–¥–∞–Ω —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π OHLC –∏–∑ —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è")
            
        elif format_type == 'indicators_only':
            raise ValueError("–î–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ–ª—å–∫–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –±–µ–∑ —Ü–µ–Ω. –ù—É–∂–Ω—ã OHLCV –¥–∞–Ω–Ω—ã–µ.")
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö. –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º volume –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
        if 'volume' not in df.columns:
            df['volume'] = np.random.randint(1000000, 10000000, len(df))
            logger.info("–î–æ–±–∞–≤–ª–µ–Ω —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤")
        
        return df
    
    @staticmethod
    def debug_dataframe(df: pd.DataFrame, name: str = "DataFrame"):
        """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ DataFrame"""
        logger.info(f"\nüîç DEBUG: {name}")
        logger.info(f"–†–∞–∑–º–µ—Ä: {df.shape}")
        logger.info(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
        
        for col in df.columns:
            dtype = df[col].dtype
            non_null = df[col].count()
            null_count = len(df) - non_null
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è object –∫–æ–ª–æ–Ω–æ–∫
            if dtype == 'object' and non_null > 0:
                sample_values = df[col].dropna().head(2).tolist()
                logger.info(f"  {col}: {dtype} (non-null: {non_null}, null: {null_count}) –ø—Ä–∏–º–µ—Ä—ã: {sample_values}")
            else:
                logger.info(f"  {col}: {dtype} (non-null: {non_null}, null: {null_count})")
        
        # –í—ã—è–≤–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
        object_cols = df.select_dtypes(include=['object']).columns
        if len(object_cols) > 0:
            logger.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã object –∫–æ–ª–æ–Ω–∫–∏: {list(object_cols)}")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
        for col in df.columns:
            if df[col].dtype == 'object':
                unique_types = set(type(x).__name__ for x in df[col].dropna().head(10))
                if len(unique_types) > 1:
                    logger.warning(f"‚ö†Ô∏è –°–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –≤ {col}: {unique_types}")