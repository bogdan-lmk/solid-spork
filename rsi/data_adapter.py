"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ CSV –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
"""
import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__)

class DataAdapter:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ CSV –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def detect_format(df: pd.DataFrame) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö"""
        columns = set(df.columns.str.lower())
        
        if {'open', 'high', 'low', 'close'}.issubset(columns):
            return 'ohlcv'
        elif {'choppiness_index', 'volatility_percent', 'rsi_delta'}.issubset(columns):
            return 'indicators_only'
        elif 'close' in columns:
            return 'price_only'
        else:
            return 'unknown'
    
    @staticmethod
    def load_csv(filepath: str, **kwargs) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ CSV —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
            for sep in [',', ';', '\t']:
                try:
                    df = pd.read_csv(filepath, sep=sep, **kwargs)
                    if len(df.columns) > 1:  # –£—Å–ø–µ—à–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
                        logger.info(f"CSV –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}', –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
                        return df
                except Exception:
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø—è—Ç—É—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            df = pd.read_csv(filepath, **kwargs)
            logger.info(f"CSV –∑–∞–≥—Ä—É–∂–µ–Ω —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
            return df
            
        except Exception as e:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª: {e}")
    
    @staticmethod
    def clean_accumulated_data(df: pd.DataFrame) -> pd.DataFrame:
        """–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ accumulatedData —Ñ–∞–π–ª–æ–≤ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)"""
        df = df.copy()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        time_columns = ['open_time', 'close_time']
        for col in time_columns:
            if col in df.columns:
                try:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                    logger.info(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ {col} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É {col}: {e}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–ò–°–ö–õ–Æ–ß–ê–Ø –≤—Ä–µ–º–µ–Ω–Ω—ã–µ)
        numeric_columns = [
            'open', 'high', 'low', 'close', 'volume',
            'atr', 'atr_stop', 'atr_to_price_ratio',
            'fast_ema', 'slow_ema', 'ema_fast_deviation',
            'pchange', 'avpchange', 'gma', 'gma_smoothed',
            'positionBetweenBands', 'bollinger_position',
            'choppiness_index', 'volatility_percent',
            'rsi_volatility', 'adx', 'rsi_divergence', 'rsi_delta', 'linear_regression'
        ]
        
        # –ì–õ–ê–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∏—Å–∫–ª—é—á–∞—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ
        for col in numeric_columns:
            if col in df.columns and col not in time_columns:  # –ò—Å–∫–ª—é—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏!
                try:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –∏ –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏
                    df[col] = df[col].astype(str).str.replace(',', '.', regex=False)
                    
                    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –¥—Ä—É–≥–∏–µ —Å–∏–º–≤–æ–ª—ã
                    df[col] = df[col].str.strip()
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    logger.debug(f"–ö–æ–ª–æ–Ω–∫–∞ {col} –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø")
                    
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É {col}: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
        if 'open_time' in df.columns and not df['open_time'].isna().all():
            try:
                df = df.sort_values('open_time').reset_index(drop=True)
                logger.info("–î–∞–Ω–Ω—ã–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ open_time")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {e}")
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –∫—Ä–∏—Ç–∏—á–Ω—ã–º–∏ NaN (–≤ OHLC)
        critical_columns = ['open', 'high', 'low', 'close']
        available_critical = [col for col in critical_columns if col in df.columns]
        
        if available_critical:
            before_rows = len(df)
            df = df.dropna(subset=available_critical)
            after_rows = len(df)
            
            if before_rows != after_rows:
                logger.info(f"–£–¥–∞–ª–µ–Ω–æ {before_rows - after_rows} —Å—Ç—Ä–æ–∫ —Å NaN –≤ OHLC –¥–∞–Ω–Ω—ã—Ö")
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö NaN –≤ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            df[numeric_cols] = df[numeric_cols].ffill().bfill()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {df.shape}")
        logger.info(f"–ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {len(df.select_dtypes(include=[np.number]).columns)}")
        logger.info(f"–í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {len(df.select_dtypes(include=['datetime64']).columns)}")
        
        return df
    
    @staticmethod
    def adapt_to_ohlcv(df: pd.DataFrame) -> pd.DataFrame:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∫ —Ñ–æ—Ä–º–∞—Ç—É OHLCV"""
        df = df.copy()
        format_type = DataAdapter.detect_format(df)
        
        if format_type == 'ohlcv':
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ accumulatedData
            if 'open_time' in df.columns and 'atr' in df.columns:
                logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ accumulatedData - –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É")
                df = DataAdapter.clean_accumulated_data(df)
            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ OHLCV
                required_cols = ['open', 'high', 'low', 'close']
                df = df.rename(columns={col: col.lower() for col in df.columns})
                
                missing = [col for col in required_cols if col not in df.columns]
                if missing:
                    raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing}")
                    
        elif format_type == 'price_only':
            # –¢–æ–ª—å–∫–æ —Ü–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è - —Å–æ–∑–¥–∞–µ–º OHLC
            if 'close' not in df.columns:
                raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'close'")
            
            df['open'] = df['close'].shift(1).fillna(df['close'].iloc[0])
            df['high'] = df[['open', 'close']].max(axis=1) * (1 + np.random.uniform(0, 0.01, len(df)))
            df['low'] = df[['open', 'close']].min(axis=1) * (1 - np.random.uniform(0, 0.01, len(df)))
            
            logger.info("–°–æ–∑–¥–∞–Ω —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π OHLC –∏–∑ —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è")
            
        elif format_type == 'indicators_only':
            raise ValueError("–î–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ–ª—å–∫–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –±–µ–∑ —Ü–µ–Ω. –ù—É–∂–Ω—ã OHLCV –¥–∞–Ω–Ω—ã–µ.")
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö. –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º volume –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
        if 'volume' not in df.columns:
            df['volume'] = np.random.randint(1000000, 10000000, len(df))
            logger.info("–î–æ–±–∞–≤–ª–µ–Ω —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤")
        
        return df
    
    @staticmethod
    def debug_dataframe(df: pd.DataFrame, name: str = "DataFrame"):
        """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ DataFrame"""
        logger.info(f"\nüîç DEBUG: {name}")
        logger.info(f"–†–∞–∑–º–µ—Ä: {df.shape}")
        logger.info(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
        
        for col in df.columns:
            dtype = df[col].dtype
            non_null = df[col].count()
            null_count = len(df) - non_null
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è object –∫–æ–ª–æ–Ω–æ–∫
            if dtype == 'object' and non_null > 0:
                sample_values = df[col].dropna().head(2).tolist()
                logger.info(f"  {col}: {dtype} (non-null: {non_null}, null: {null_count}) –ø—Ä–∏–º–µ—Ä—ã: {sample_values}")
            else:
                logger.info(f"  {col}: {dtype} (non-null: {non_null}, null: {null_count})")
        
        # –í—ã—è–≤–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
        object_cols = df.select_dtypes(include=['object']).columns
        if len(object_cols) > 0:
            logger.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã object –∫–æ–ª–æ–Ω–∫–∏: {list(object_cols)}")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
        for col in df.columns:
            if df[col].dtype == 'object':
                unique_types = set(type(x).__name__ for x in df[col].dropna().head(10))
                if len(unique_types) > 1:
                    logger.warning(f"‚ö†Ô∏è –°–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –≤ {col}: {unique_types}")

def validate_ohlcv_data(df: pd.DataFrame) -> pd.DataFrame:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è OHLCV –¥–∞–Ω–Ω—ã—Ö"""
    required_columns = ['open', 'high', 'low', 'close']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π OHLC
    df_clean = df.copy()
    
    # High –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å >= max(open, close)
    invalid_high = df_clean['high'] < df_clean[['open', 'close']].max(axis=1)
    if invalid_high.any():
        logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {invalid_high.sum()} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º high")
        df_clean.loc[invalid_high, 'high'] = df_clean.loc[invalid_high, ['open', 'close']].max(axis=1)
    
    # Low –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å <= min(open, close)
    invalid_low = df_clean['low'] > df_clean[['open', 'close']].min(axis=1)
    if invalid_low.any():
        logger.warning(f"–ù–∞–π–¥–µ–Ω–æ {invalid_low.sum()} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º low")
        df_clean.loc[invalid_low, 'low'] = df_clean.loc[invalid_low, ['open', 'close']].min(axis=1)
    
    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏
    negative_prices = (df_clean[['open', 'high', 'low', 'close']] <= 0).any(axis=1)
    if negative_prices.any():
        logger.warning(f"–£–¥–∞–ª–µ–Ω–æ {negative_prices.sum()} —Å—Ç—Ä–æ–∫ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏")
        df_clean = df_clean[~negative_prices]
    
    return df_clean

def convert_numeric_columns(df: pd.DataFrame, columns: list = None) -> pd.DataFrame:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    df_result = df.copy()
    
    if columns is None:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        columns = [col for col in df.columns if col not in ['open_time', 'close_time']]
    
    for col in columns:
        if col in df_result.columns:
            try:
                # –ï—Å–ª–∏ —É–∂–µ —á–∏—Å–ª–æ–≤–∞—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if pd.api.types.is_numeric_dtype(df_result[col]):
                    continue
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –∏ –æ—á–∏—â–∞–µ–º
                series = df_result[col].astype(str)
                
                # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ (–µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç)
                series = series.str.replace(',', '.', regex=False)
                
                # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã
                series = series.str.strip()
                
                # –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –≤–∞–ª—é—Ç –∏ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
                series = series.str.replace(r'[‚Ç¨$%]', '', regex=True)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º 'nan', 'null', –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                series = series.replace(['nan', 'null', 'NaN', 'NULL', ''], np.nan)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                df_result[col] = pd.to_numeric(series, errors='coerce')
                
                logger.debug(f"–ö–æ–ª–æ–Ω–∫–∞ {col} —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç")
                
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É {col}: {e}")
    
    return df_result

def detect_decimal_separator(df: pd.DataFrame, sample_columns: list = None) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–µ—Å—è—Ç–∏—á–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –≤ –¥–∞–Ω–Ω—ã—Ö"""
    if sample_columns is None:
        sample_columns = ['open', 'high', 'low', 'close', 'volume']
    
    comma_count = 0
    dot_count = 0
    
    for col in sample_columns:
        if col in df.columns:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 100 –Ω–µ-null –∑–Ω–∞—á–µ–Ω–∏–π
            sample_data = df[col].dropna().head(100).astype(str)
            
            for value in sample_data:
                if ',' in value and '.' in value:
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –∏ –∑–∞–ø—è—Ç–∞—è –∏ —Ç–æ—á–∫–∞, –≤–µ—Ä–æ—è—Ç–Ω–æ –∑–∞–ø—è—Ç–∞—è - —Ç—ã—Å—è—á–∏, —Ç–æ—á–∫–∞ - –¥–µ—Å—è—Ç–∏—á–Ω–∞—è
                    dot_count += 1
                elif ',' in value:
                    comma_count += 1
                elif '.' in value:
                    dot_count += 1
    
    if comma_count > dot_count:
        logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª (–∑–∞–ø—è—Ç–∞—è –∫–∞–∫ –¥–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å)")
        return ','
    else:
        logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç —á–∏—Å–µ–ª (—Ç–æ—á–∫–∞ –∫–∞–∫ –¥–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å)")
        return '.'

def clean_data_auto(df: pd.DataFrame) -> pd.DataFrame:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞"""
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö")
    
    df_clean = df.copy()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–µ—Å—è—Ç–∏—á–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    decimal_sep = detect_decimal_separator(df_clean)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    if decimal_sep == ',':
        # –ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç - –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏
        df_clean = convert_numeric_columns(df_clean)
    else:
        # –ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
        df_clean = convert_numeric_columns(df_clean)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    time_columns = ['open_time', 'close_time', 'timestamp', 'date', 'time']
    for col in time_columns:
        if col in df_clean.columns:
            try:
                df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')
                logger.info(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ {col} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É {col}: {e}")
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è OHLCV –µ—Å–ª–∏ —ç—Ç–æ —Ç–æ—Ä–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    if all(col in df_clean.columns for col in ['open', 'high', 'low', 'close']):
        try:
            df_clean = validate_ohlcv_data(df_clean)
            logger.info("OHLCV –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ OHLCV: {e}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
    initial_rows = len(df_clean)
    
    # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    df_clean = df_clean.dropna(how='all')
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        df_clean[numeric_cols] = df_clean[numeric_cols].ffill().bfill()
    
    final_rows = len(df_clean)
    
    if initial_rows != final_rows:
        logger.info(f"–£–¥–∞–ª–µ–Ω–æ {initial_rows - final_rows} —Å—Ç—Ä–æ–∫ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ—á–∏—Å—Ç–∫–∏")
    
    logger.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {df_clean.shape}")
    
    return df_clean