"""
–ì–ª–∞–≤–Ω—ã–π –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª –¥–ª—è RSI –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
"""
import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ Python path (absolute path)
sys.path.insert(0, os.path.abspath(str(Path(__file__).parent)))

import logging
import warnings

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore')

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    current_dir = Path(__file__).parent
    
    print("üöÄ RSI Predictor - –°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è RSI")
    print("=" * 60)
    
    try:
        # –ò–º–ø–æ—Ä—Ç—ã –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏—Ä–∫—É–ª—è—Ä–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
        from config import ModelConfig
        from rsi_predictor import RSIPredictor
        from utilities import (
            analyze_your_csv, 
            train_on_accumulated_data, 
            integrate_with_existing_data,
            create_test_data
        )
        from data_adapter import DataAdapter
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        print(f"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ: {current_dir}")
        print(f"üìÅ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
        return
    
    # 1. –ê–ù–ê–õ–ò–ó –í–ê–®–ò–• –î–ê–ù–ù–´–•
    print("\nüîç –ê–Ω–∞–ª–∏–∑ –≤–∞—à–∏—Ö CSV —Ñ–∞–π–ª–æ–≤:")
    
    # –ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π
    csv_search_paths = [
        current_dir,  # –¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞
        current_dir.parent,  # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –ø–∞–ø–∫–∞
        Path.cwd()  # –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
    ]
    
    found_files = []
    target_files = [
        "accumulatedData_2024.csv",
        "accumulatedData_2025.csv",
        "data.csv"
    ]
    
    for search_path in csv_search_paths:
        for target_file in target_files:
            file_path = search_path / target_file
            if file_path.exists():
                found_files.append(str(file_path))
                print(f"üìÅ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {file_path}")
    
    if not found_files:
        print("‚ö†Ô∏è CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö")
        print("üîç –ò—â–µ–º –ª—é–±—ã–µ CSV —Ñ–∞–π–ª—ã...")
        
        # –ò—â–µ–º –ª—é–±—ã–µ CSV —Ñ–∞–π–ª—ã
        for search_path in csv_search_paths:
            csv_files = list(search_path.glob("*.csv"))
            if csv_files:
                print(f"üìÅ –ù–∞–π–¥–µ–Ω—ã CSV —Ñ–∞–π–ª—ã –≤ {search_path}:")
                for csv_file in csv_files[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                    print(f"  - {csv_file.name}")
                    found_files.append(str(csv_file))
                break
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    for csv_file in found_files[:3]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3
        try:
            print(f"\n--- –ê–Ω–∞–ª–∏–∑ {Path(csv_file).name} ---")
            analyze_your_csv(csv_file)
        except FileNotFoundError:
            print(f"–§–∞–π–ª {csv_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {csv_file}: {e}")
    
    # 2. –û–ë–£–ß–ï–ù–ò–ï –ù–ê –î–ê–ù–ù–´–•
    print(f"\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ RSI –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞...")
    
    trained_successfully = False
    
    # –ü—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å—Å—è –Ω–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
    for csv_file in found_files[:2]:  # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–≤—ã–µ 2 —Ñ–∞–π–ª–∞
        try:
            print(f"\nüìä –ü–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {Path(csv_file).name}...")
            
            # –û–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
            predictor = integrate_with_existing_data(csv_file)
            
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –Ω–∞ {Path(csv_file).name}")
            
            # –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            df = DataAdapter.load_csv(csv_file)
            result = predictor.predict(df, return_confidence=True)
            print(f"üîÆ –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {result}")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            print(f"\nüìä –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
            importance_df = predictor.get_feature_importance(10)
            if not importance_df.empty:
                for idx, row in importance_df.iterrows():
                    print(f"  {row['feature']:<25} - {row['importance']:.4f}")
            
            trained_successfully = True
            break
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {Path(csv_file).name}: {e}")
            continue
    
    # 3. FALLBACK - —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏
    if not trained_successfully:
        print(f"\n‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        print(f"üîß –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å...")
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ fallback
            df = create_test_data(500)
            
            from config import ModelConfig
            config = ModelConfig(model_type='catboost', test_size=0.2, cv_folds=3)
            predictor = RSIPredictor(config)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π
            models_dir = current_dir / "models"
            models_dir.mkdir(exist_ok=True)
            
            metrics = predictor.train(df, save_path=str(models_dir / "rsi_predictor_fallback.pkl"))
            result = predictor.predict(df, return_confidence=True)
            
            print(f"‚úÖ –¢–µ—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
            print(f"üîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
            trained_successfully = True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            import traceback
            print(traceback.format_exc())
    
    # 4. –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –†–ï–ó–£–õ–¨–¢–ê–¢–ê–•
    if trained_successfully:
        models_dir = current_dir / "models"
        if models_dir.exists():
            model_files = list(models_dir.glob("*.pkl"))
            print(f"\nüìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ {models_dir}:")
            for model_file in model_files:
                print(f"  - {model_file.name}")
    
    print(f"\nüéâ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    print(f"\nüìã –ü–æ–ª–µ–∑–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
    print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {current_dir}")
    print(f"üêç Python path: {sys.path[0]}")
    print(f"üíæ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")

if __name__ == "__main__":
    main()
